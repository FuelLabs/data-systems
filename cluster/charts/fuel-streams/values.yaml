# ------------------------------------------------------------------------------
# Global Config
# ------------------------------------------------------------------------------

config:
  labels: {}
  annotations: {}
  # Override the name and fullname of the chart
  nameOverride: ""
  fullnameOverride: ""

  # Enable probes and health checks for all services
  healthChecks: true
  # Enable Prometheus for all services
  prometheus:
    enabled: true
    dataSource: "DS__PROMETHEUS"

  # Default liveness probe
  livenessProbe:
    enabled: true
    httpGet:
      path: /api/v1/health
      port: http
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3

  # Default readiness probe
  readinessProbe:
    enabled: true
    httpGet:
      path: /api/v1/health
      port: http
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3

  # Default startup probe
  startupProbe:
    enabled: true
    httpGet:
      path: /api/v1/health
      port: http
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3

  # Default pod security context
  podSecurityContext:
    fsGroup: 1000
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    capabilities:
      drop: [ALL]
    readOnlyRootFilesystem: true

  # Default container security context
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    capabilities:
      drop: [ALL]
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false

  # Default pod affinity
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: publisher
            topologyKey: topology.kubernetes.io/zone

  # Default autoscaling configuration
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80

  # Default service configuration
  service:
    port: 8080
    type: ClusterIP

# ------------------------------------------------------------------------------
# Global ConfigMap
# ------------------------------------------------------------------------------

commonConfigMap:
  enabled: true
  data:
    USE_METRICS: "false"
    NATS_URL: "fuel-streams-nats:4222"
    NATS_SYSTEM_USER: "sys"
    NATS_SYSTEM_PASS: "sys"
    NATS_ADMIN_USER: "admin"
    NATS_ADMIN_PASS: "admin"
    # For local purposes only, for production use fuel-streams-keys secret
    DB_TYPE: "Aurora"
    DATABASE_URL: "postgresql://postgres:postgres@127.0.0.1:5432/fuel_streams?sslmode=disable"

# This is a secret that is used for local development
# It is not used in production
localSecrets:
  enabled: false
  data: {}

# ------------------------------------------------------------------------------
# ServiceAccount
# ------------------------------------------------------------------------------

serviceAccount:
  create: true
  automount: true

# ------------------------------------------------------------------------------
# Publisher configuration
# ------------------------------------------------------------------------------

publisher:
  enabled: true
  network: mainnet

  ports: []
  port: 8080

  image:
    repository: ghcr.io/fuellabs/sv-publisher
    pullPolicy: Always
    tag: latest
    args: []

  # You can override the env variables for the container here
  # using a map or an array of key-value pairs
  envFrom: []
  env:
    TMPDIR: "/var/fuel-streams/tmp"
    DB_PATH: /mnt/db
    FUEL_CORE_PORT: 4004

  service:
    enabled: true
    port: 8080
    type: ClusterIP
    config:
      annotations: {}
      labels: {}

  prometheus:
    enabled: true
    scrape: true
    path: /api/v1/metrics
    config:
      annotations: {}
      labels:
        release: kube-prometheus-stack

  storage:
    name: rocks-db
    size: 500Gi
    storageClass: "gp3-generic"
    accessMode: ReadWriteOnce
    mountPath: /mnt/db

  config:
    replicaCount: 1
    labels: {}
    annotations: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    imagePullSecrets: []
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
    readinessProbe:
      httpGet:
        path: /health
        port: 8080
    startupProbe:
      httpGet:
        path: /health
        port: 8080
    podSecurityContext: {}
    containerSecurityContext: {}
    resources: {}

  autoscaling:
    enabled: false

# ------------------------------------------------------------------------------
# Consumer configuration
# ------------------------------------------------------------------------------

consumer:
  enabled: true
  network: mainnet

  port: 8080
  ports: []

  image:
    repository: ghcr.io/fuellabs/sv-consumer
    pullPolicy: Always
    tag: latest
    args: []

  # You can override the env variables for the container here
  # using a map or an array of key-value pairs
  envFrom: []
  env: {}

  service:
    enabled: true
    port: 8080
    type: ClusterIP
    config:
      annotations: {}
      labels: {}

  prometheus:
    enabled: true
    scrape: true
    path: /api/v1/metrics
    config:
      annotations: {}
      labels:
        release: kube-prometheus-stack

  config:
    replicaCount: 3
    labels: {}
    annotations: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    imagePullSecrets: []
    livenessProbe: {}
    readinessProbe: {}
    startupProbe: {}
    podSecurityContext: {}
    containerSecurityContext: {}
    resources: {}

  autoscaling:
    enabled: false

# ------------------------------------------------------------------------------
# Webserver configuration
# ------------------------------------------------------------------------------

webserver:
  enabled: true
  network: mainnet

  port: 8080
  ports: []

  image:
    repository: ghcr.io/fuellabs/sv-webserver
    pullPolicy: Always
    tag: latest

  service:
    enabled: true
    port: 8080
    type: ClusterIP
    host: "stream-staging.fuel.network"
    config:
      annotations: {}
      labels: {}

  prometheus:
    enabled: true
    scrape: true
    path: /api/v1/metrics
    config:
      annotations: {}
      labels:
        release: kube-prometheus-stack

  tls:
    enabled: true
    certificate:
      issuer: letsencrypt-prod
      duration: 2160h
      renewBefore: 360h
      config:
        annotations: {}
        labels: {}
    ingress:
      config:
        annotations: {}
        labels: {}

  # You can override the env variables for the container here
  # using a map or an array of key-value pairs
  envFrom: []
  env: {}

  config:
    replicaCount: 3
    labels: {}
    annotations: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    imagePullSecrets: []
    livenessProbe: {}
    readinessProbe: {}
    startupProbe: {}
    podSecurityContext: {}
    containerSecurityContext: {}
    resources: {}

  autoscaling:
    enabled: true


# ------------------------------------------------------------------------------
# Api configuration
# ------------------------------------------------------------------------------

api:
  enabled: true
  network: mainnet

  port: 8080
  ports: []

  image:
    repository: ghcr.io/fuellabs/sv-api
    pullPolicy: Always
    tag: latest

  service:
    enabled: true
    port: 8080
    type: ClusterIP
    host: "stream-staging.fuel.network"
    config:
      annotations: {}
      labels: {}

  prometheus:
    enabled: true
    scrape: true
    path: /api/v1/metrics
    config:
      annotations: {}
      labels:
        release: kube-prometheus-stack

  tls:
    enabled: true
    certificate:
      issuer: letsencrypt-prod
      duration: 2160h
      renewBefore: 360h
      config:
        annotations: {}
        labels: {}
    ingress:
      config:
        annotations: {}
        labels: {}

  # You can override the env variables for the container here
  # using a map or an array of key-value pairs
  envFrom: []
  env: {}

  config:
    replicaCount: 3
    labels: {}
    annotations: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    imagePullSecrets: []
    livenessProbe: {}
    readinessProbe: {}
    startupProbe: {}
    podSecurityContext: {}
    containerSecurityContext: {}
    resources: {}

  autoscaling:
    enabled: true

# ------------------------------------------------------------------------------
# NATS Core configuration
# ------------------------------------------------------------------------------

nats:
  enabled: true

  natsBox:
    enabled: false

  promExporter:
    enabled: true
    port: 6777
    image:
      repository: natsio/prometheus-nats-exporter
      tag: 0.15.0
    podMonitor:
      enabled: true
      merge:
        metadata:
          labels:
            release: kube-prometheus-stack

  container:
    image:
      repository: nats
      tag: 2.10.24-alpine
    env:
      GOMEMLIMIT: 7GiB
    merge:
      resources:
        requests:
          cpu: 2
          memory: 8Gi

  service:
    enabled: true
    ports:
      nats:
        enabled: true
      cluster:
        enabled: true
      monitor:
        enabled: true

  config:
    cluster:
      enabled: true
      port: 6222
      replicas: 5
      routeURLs:
        useFQDN: true

    jetstream:
      enabled: true
      fileStore:
        dir: /data
        pvc:
          enabled: true
          size: 100Gi
          storageClassName: "gp3-generic"

    monitor:
      enabled: true
      port: 8222

    merge:
      max_payload: << 8MiB >>
      jetstream:
        max_file_store: << 100GiB >>
        max_memory_store: << 7GiB >>
      system_account: SYS
      $include: auth.conf

  statefulSet:
    merge:
      spec:
        affinity:
          $tplYaml: |
            {{- include "k8s.pod-config.affinityy" . | nindent 4 }}

  configMap:
    merge:
      $tplYaml: |
        {{- include "nats-accounts" . | nindent 8 }}

# ------------------------------------------------------------------------------
# Prometheus & Monitoring configuration
# ------------------------------------------------------------------------------

prometheus:
  enabled: false

  # Prometheus Operator configuration
  prometheusOperator:
    enabled: true
    serviceAccount:
      create: true
    admissionWebhooks:
      enabled: true
    tls:
      enabled: false

  # Prometheus server configuration
  prometheus:
    enabled: true
    prometheusSpec:
      podMonitorSelectorNilUsesHelmValues: false
      serviceMonitorSelectorNilUsesHelmValues: false
    serviceAccount:
      create: true
    serviceMonitor:
      enabled: true
    ingress:
      enabled: false
    retention: 10d
    resources:
      requests:
        memory: 256Mi
        cpu: 100m
      limits:
        memory: 512Mi
        cpu: 500m

  # Alertmanager configuration
  alertmanager:
    enabled: true
    serviceAccount:
      create: true
    ingress:
      enabled: false
    resources:
      requests:
        memory: 128Mi
        cpu: 50m
      limits:
        memory: 256Mi
        cpu: 200m

  # Grafana configuration
  grafana:
    enabled: true
    adminPassword: admin
    ingress:
      enabled: false
    persistence:
      enabled: true
      storageClassName: gp3-generic
      accessModes:
        - ReadWriteOnce
      size: 10Gi
      finalizers:
        - kubernetes.io/pvc-protection
    resources:
      requests:
        memory: 128Mi
        cpu: 100m
      limits:
        memory: 256Mi
        cpu: 200m
    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        labelValue: "1"
        searchNamespace: ALL
        folderAnnotation: "grafana_folder"
        provider:
          foldersFromFilesStructure: true
        defaultFolderName: "Fuel Streams"

  # Node exporter for hardware and OS metrics
  nodeExporter:
    enabled: true
    resources:
      requests:
        memory: 32Mi
        cpu: 50m
      limits:
        memory: 64Mi
        cpu: 100m

  # Kubelet metrics
  kubelet:
    enabled: true
    serviceMonitor:
      https: true

  # Default scrape configs
  defaultRules:
    create: true
    rules:
      alertmanager: true
      etcd: true
      general: true
      k8s: true
      kubeApiserver: true
      kubePrometheusNodeAlerting: true
      kubePrometheusNodeRecording: true
      kubernetesAbsent: true
      kubernetesApps: true
      kubernetesResources: true
      kubernetesStorage: true
      kubernetesSystem: true
      kubeScheduler: true
      network: true
      node: true
      prometheus: true
